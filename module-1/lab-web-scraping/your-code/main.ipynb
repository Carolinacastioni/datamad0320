{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "# from urllib.request import urlopen\n",
    "# import random\n",
    "# import re\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "res.text\n",
    "\n",
    "soup = BeautifulSoup(res.text)\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "# <article class=\"Box-row d-flex\" id=\"pa-nornagon\">  \n",
    "\n",
    "#2. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "dev_names = soup.select(\"article.Box-row.d-flex h1\")\n",
    "#print(dev_names[0].text)\n",
    "\n",
    "lst = []\n",
    "for e in dev_names:\n",
    "    lst.append(e.text)\n",
    "#print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. \\n) \n",
    "#in the text of each html element. Use a list to store the clean names.\n",
    "\n",
    "names = [n.strip(\"\\n\").strip() for n in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jeremy Apthorp',\n",
       " 'jonesforth',\n",
       " 'Jonah Williams',\n",
       " 'json_widget',\n",
       " 'Felix Angelov',\n",
       " 'bloc',\n",
       " 'chencheng (云谦)',\n",
       " 'awesome-javascript',\n",
       " 'Sebastián Ramírez',\n",
       " 'fastapi',\n",
       " 'Mariusz Nowak',\n",
       " 'memoizee',\n",
       " 'Dawid Urbaniak',\n",
       " 'twitterClone',\n",
       " 'Jeffrey Su',\n",
       " 'WeiXinMPSDK',\n",
       " 'Hugo Bowne-Anderson',\n",
       " 'COVID-19-EDA-tutorial',\n",
       " 'Felipe Fialho',\n",
       " 'frontend-challenges',\n",
       " 'Yuri Shkuro',\n",
       " 'opentracing-tutorial',\n",
       " 'R.I.Pienaar',\n",
       " 'free-for-dev',\n",
       " 'Zeno Rocha',\n",
       " 'clipboard.js',\n",
       " 'Maxim Kulkin',\n",
       " 'esp-homekit-demo',\n",
       " 'Robert Mosolgo',\n",
       " 'graphql-ruby',\n",
       " 'Pierre Krieger',\n",
       " 'redshirt',\n",
       " 'Iman',\n",
       " 'laravel-widgetize',\n",
       " 'Luis Alvarez D.',\n",
       " 'next-with-apollo',\n",
       " 'Matic Zavadlal',\n",
       " 'graphql-shield',\n",
       " 'Marten Seemann',\n",
       " 'quic-conn',\n",
       " 'David Peter',\n",
       " 'bat',\n",
       " 'Jake Wharton',\n",
       " 'butterknife',\n",
       " 'Jeff Bezanson',\n",
       " 'femtolisp',\n",
       " 'James Munnelly',\n",
       " 'kube-plex',\n",
       " 'Matthew Johnson',\n",
       " 'pyhsmm']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Print the list of names.\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "res.text\n",
    "\n",
    "soup = BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rojter-tech/pluradl.py',\n",
       " 'caoscott/SReC',\n",
       " '0voice/interview_internal_reference',\n",
       " 'ageitgey/face_recognition',\n",
       " 'manchenkoff/skillbox-async-chat',\n",
       " 'XiaohangZhan/deocclusion',\n",
       " 'google-research/text-to-text-transfer-transformer',\n",
       " 'kon9chunkit/GitHub-Chinese-Top-Charts',\n",
       " 'tiangolo/fastapi',\n",
       " 'CorentinJ/Real-Time-Voice-Cloning',\n",
       " 'home-assistant/core',\n",
       " 'alex04072000/ObstructionRemoval',\n",
       " 'pcomputo/Whole-Foods-Delivery-Slot',\n",
       " 'CharlesPikachu/Games',\n",
       " 'doccano/doccano',\n",
       " 'google/jax',\n",
       " 'hankcs/HanLP',\n",
       " 'Sentdex/pygta5',\n",
       " 'ray-project/ray',\n",
       " 'Yelp/elastalert',\n",
       " 'timgrossmann/InstaPy',\n",
       " 'huggingface/transformers',\n",
       " 'ikergarcia1996/Self-Driving-Car-in-Video-Games',\n",
       " 'fizyr/keras-retinanet',\n",
       " 'apache/airflow']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names = soup.select(\"article.Box-row h1\")\n",
    "#print(repo_names[0].text)\n",
    "\n",
    "repo_lst = []\n",
    "for r in repo_names:\n",
    "    repo_lst.append(r.text)\n",
    "    #print(repo_lst)\n",
    "    \n",
    "repos = [rep.strip(\"\\n\").strip() for rep in repo_lst]\n",
    "#print(repos)\n",
    "\n",
    "repositories = [x.replace(\"\\n\", \"\").replace(\" \", \"\") for x in repos]\n",
    "repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_res = requests.get(url)\n",
    "\n",
    "d_soup = BeautifulSoup(d_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAER TODOS DE CLASS IMAGE = .CLASSNAME\n",
    "\n",
    "disney_images = d_soup.select(\".image\")\n",
    "#disney_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/File:Walt_Disney_1946.JPG',\n",
       " '/wiki/File:Walt_Disney_1942_signature.svg',\n",
       " '/wiki/File:Walt_Disney_envelope_ca._1921.jpg',\n",
       " '/wiki/File:Trolley_Troubles_poster.jpg',\n",
       " '/wiki/File:Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " '/wiki/File:Steamboat-willie.jpg',\n",
       " '/wiki/File:Walt_Disney_1935.jpg',\n",
       " '/wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg',\n",
       " '/wiki/File:Disney_drawing_goofy.jpg',\n",
       " '/wiki/File:DisneySchiphol1951.jpg',\n",
       " '/wiki/File:WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '/wiki/File:Walt_disney_portrait_right.jpg',\n",
       " '/wiki/File:Walt_Disney_Grave.JPG',\n",
       " '/wiki/File:Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " '/wiki/File:Disney_Display_Case.JPG',\n",
       " '/wiki/File:Disney1968.jpg',\n",
       " '/wiki/File:The_Walt_Disney_Company_Logo.svg',\n",
       " '/wiki/File:Animation_disc.svg',\n",
       " '/wiki/File:P_vip.svg',\n",
       " '/wiki/File:Magic_Kingdom_castle.jpg',\n",
       " '/wiki/File:Video-x-generic.svg',\n",
       " '/wiki/File:Flag_of_Los_Angeles_County,_California.svg',\n",
       " '/wiki/File:Blank_television_set.svg',\n",
       " '/wiki/File:Flag_of_the_United_States.svg']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = [d[\"href\"] for d in disney_images]\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_res = requests.get(url)\n",
    "\n",
    "wiki_soup = BeautifulSoup(wiki_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>,\n",
       " <a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>,\n",
       " <a class=\"extiw\" href=\"https://en.wiktionary.org/wiki/Python\" title=\"wiktionary:Python\">Python</a>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_links = wiki_soup.select(\"a[href]\")\n",
    "wiki_links[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#mw-head',\n",
       " '#p-search',\n",
       " 'https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " '#Snakes']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = [w[\"href\"] for w in wiki_links]\n",
    "links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_res = requests.get(url)\n",
    "\n",
    "usa_soup = BeautifulSoup(usa_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"usctitlechanged\" id=\"us/usc/t8\">\n",
       "\n",
       "          Title 8 - Aliens and Nationality\n",
       "\n",
       "        </div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_title = usa_soup.select(\".usctitlechanged\")\n",
    "usa_title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "usa_lst = [u for u in usa_title]\n",
    "print(len(usa_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbi_res = requests.get(url)\n",
    "\n",
    "fbi_soup = BeautifulSoup(fbi_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYASER ABDEL SAID\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi = fbi_soup.select(\".title\")\n",
    "fbi[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YASER ABDEL SAID',\n",
       " 'ALEXIS FLORES',\n",
       " 'EUGENE PALMER',\n",
       " 'SANTIAGO VILLALBA MEDEROS',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'JASON DEREK BROWN']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wanted = [name.text.strip().strip(\"\\n\") for name in fbi]\n",
    "most_wanted[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_res = requests.get(url)\n",
    "\n",
    "eq_soup = BeautifulSoup(eq_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '\\n\\n\\n\\n\\nset_server_date(2020,4,9,19,26,42)\\nCurrent time: 2020-04-09 19:26:42 UTC\\n',\n",
       " '\\n\\n\\xa0Member access\\n\\nName\\xa0\\n\\n\\nPwd\\n\\n\\n\\xa0',\n",
       " '\\n\\xa0Member access',\n",
       " '\\n',\n",
       " 'Name\\xa0',\n",
       " '',\n",
       " '',\n",
       " 'Pwd',\n",
       " '',\n",
       " '',\n",
       " '\\xa0',\n",
       " '',\n",
       " '\\xa0- Sorting by column is performed on the data of the current page.',\n",
       " 'Glossary',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[eq.text for eq in eq_soup.select(\"table:nth-of-type(1) td\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date & time: a[href] ??\n",
    "# latitude & longitude: .tabev1 .tabev2\n",
    "# region name: .tb_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "getText = lambda eq:eq.text\n",
    "region = list(map(getText,eq_soup.select(\".tb_region\")))\n",
    "latitude = list(map(getText,eq_soup.select(\".tabev1\")))\n",
    "longitude = list(map(getText,eq_soup.select(\".tabev2\")))\n",
    "date_time = list(map(getText,eq_soup.select(\"a[href]\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORTHERN SUMATRA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOUTHERN SUMATRA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PUERTO RICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRETE, GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHAGOS ARCHIPELAGO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KEPULAUAN BABAR, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KOSOVO *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LUZON, PHILIPPINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CROATIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AZORES ISLANDS, PORTUGAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KERMADEC ISLANDS, NEW ZEALAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEAR EAST COAST OF HONSHU, JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CENTRAL ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ADRIATIC SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>OFFSHORE GUERRERO, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PHILIPPINE ISLANDS REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FOX ISLANDS, ALEUTIAN ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REVILLA GIGEDO ISLANDS REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PUERTO RICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SOUTHERN ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SLOVENIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>MINAHASA, SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NORTHERN MID-ATLANTIC RIDGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>GOLFO DE FONSECA, EL SALVADOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "0                 SOUTHERN CALIFORNIA\n",
       "1         NORTHERN SUMATRA, INDONESIA\n",
       "2          DODECANESE ISLANDS, GREECE\n",
       "3                      EASTERN TURKEY\n",
       "4         SOUTHERN SUMATRA, INDONESIA\n",
       "5                         PUERTO RICO\n",
       "6            ISLAND OF HAWAII, HAWAII\n",
       "7          DODECANESE ISLANDS, GREECE\n",
       "8                       CRETE, GREECE\n",
       "9                  PUERTO RICO REGION\n",
       "10          CHAGOS ARCHIPELAGO REGION\n",
       "11         KEPULAUAN BABAR, INDONESIA\n",
       "12                SOUTHERN CALIFORNIA\n",
       "13                           KOSOVO *\n",
       "14                 LUZON, PHILIPPINES\n",
       "15           ISLAND OF HAWAII, HAWAII\n",
       "16                            CROATIA\n",
       "17           AZORES ISLANDS, PORTUGAL\n",
       "18      KERMADEC ISLANDS, NEW ZEALAND\n",
       "19                 DOMINICAN REPUBLIC\n",
       "20   NEAR EAST COAST OF HONSHU, JAPAN\n",
       "21                     CENTRAL ALASKA\n",
       "22   NEAR THE COAST OF WESTERN TURKEY\n",
       "23                       ADRIATIC SEA\n",
       "24                           OKLAHOMA\n",
       "25          OFFSHORE GUERRERO, MEXICO\n",
       "26                 PUERTO RICO REGION\n",
       "27                     WESTERN TURKEY\n",
       "28           SOUTH OF JAVA, INDONESIA\n",
       "29          PHILIPPINE ISLANDS REGION\n",
       "30      FOX ISLANDS, ALEUTIAN ISLANDS\n",
       "31           FLORES REGION, INDONESIA\n",
       "32                    TARAPACA, CHILE\n",
       "33      REVILLA GIGEDO ISLANDS REGION\n",
       "34           SOUTH OF JAVA, INDONESIA\n",
       "35                 PUERTO RICO REGION\n",
       "36                     NORTHERN ITALY\n",
       "37                        PUERTO RICO\n",
       "38           ISLAND OF HAWAII, HAWAII\n",
       "39                    SOUTHERN ALASKA\n",
       "40                            ALBANIA\n",
       "41                 PUERTO RICO REGION\n",
       "42           SOUTH OF JAVA, INDONESIA\n",
       "43                           SLOVENIA\n",
       "44      MINAHASA, SULAWESI, INDONESIA\n",
       "45        NORTHERN MID-ATLANTIC RIDGE\n",
       "46      GOLFO DE FONSECA, EL SALVADOR\n",
       "47                SULAWESI, INDONESIA\n",
       "48                             FRANCE\n",
       "49                     SOUTHERN IDAHO"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(region)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "      <td>34.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORTHERN SUMATRA, INDONESIA</td>\n",
       "      <td>118.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>96.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOUTHERN SUMATRA, INDONESIA</td>\n",
       "      <td>35.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>27.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>38.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "      <td>38.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRETE, GREECE</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>103.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHAGOS ARCHIPELAGO REGION</td>\n",
       "      <td>17.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KEPULAUAN BABAR, INDONESIA</td>\n",
       "      <td>66.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "      <td>19.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KOSOVO *</td>\n",
       "      <td>155.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LUZON, PHILIPPINES</td>\n",
       "      <td>35.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>27.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CROATIA</td>\n",
       "      <td>34.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AZORES ISLANDS, PORTUGAL</td>\n",
       "      <td>23.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KERMADEC ISLANDS, NEW ZEALAND</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "      <td>66.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEAR EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CENTRAL ALASKA</td>\n",
       "      <td>68.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ADRIATIC SEA</td>\n",
       "      <td>129.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>33.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>OFFSHORE GUERRERO, MEXICO</td>\n",
       "      <td>116.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>42.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "      <td>20.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>15.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PHILIPPINE ISLANDS REGION</td>\n",
       "      <td>119.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FOX ISLANDS, ALEUTIAN ISLANDS</td>\n",
       "      <td>19.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>155.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "      <td>45.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REVILLA GIGEDO ISLANDS REGION</td>\n",
       "      <td>16.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>38.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>29.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "      <td>30.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>177.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SOUTHERN ALASKA</td>\n",
       "      <td>70.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>36.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>141.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>62.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SLOVENIA</td>\n",
       "      <td>150.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>MINAHASA, SULAWESI, INDONESIA</td>\n",
       "      <td>39.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NORTHERN MID-ATLANTIC RIDGE</td>\n",
       "      <td>26.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>GOLFO DE FONSECA, EL SALVADOR</td>\n",
       "      <td>41.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "      <td>19.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FRANCE</td>\n",
       "      <td>36.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "      <td>95.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0 latitude\n",
       "0                 SOUTHERN CALIFORNIA   34.59 \n",
       "1         NORTHERN SUMATRA, INDONESIA  118.80 \n",
       "2          DODECANESE ISLANDS, GREECE    4.39 \n",
       "3                      EASTERN TURKEY   96.56 \n",
       "4         SOUTHERN SUMATRA, INDONESIA   35.15 \n",
       "5                         PUERTO RICO   27.79 \n",
       "6            ISLAND OF HAWAII, HAWAII   38.22 \n",
       "7          DODECANESE ISLANDS, GREECE   38.76 \n",
       "8                       CRETE, GREECE    2.88 \n",
       "9                  PUERTO RICO REGION  103.03 \n",
       "10          CHAGOS ARCHIPELAGO REGION   17.96 \n",
       "11         KEPULAUAN BABAR, INDONESIA   66.83 \n",
       "12                SOUTHERN CALIFORNIA   19.22 \n",
       "13                           KOSOVO *  155.42 \n",
       "14                 LUZON, PHILIPPINES   35.15 \n",
       "15           ISLAND OF HAWAII, HAWAII   27.83 \n",
       "16                            CROATIA   34.69 \n",
       "17           AZORES ISLANDS, PORTUGAL   23.57 \n",
       "18      KERMADEC ISLANDS, NEW ZEALAND   17.93 \n",
       "19                 DOMINICAN REPUBLIC   66.95 \n",
       "20   NEAR EAST COAST OF HONSHU, JAPAN    5.32 \n",
       "21                     CENTRAL ALASKA   68.69 \n",
       "22   NEAR THE COAST OF WESTERN TURKEY    7.31 \n",
       "23                       ADRIATIC SEA  129.32 \n",
       "24                           OKLAHOMA   33.25 \n",
       "25          OFFSHORE GUERRERO, MEXICO  116.64 \n",
       "26                 PUERTO RICO REGION   42.11 \n",
       "27                     WESTERN TURKEY   20.70 \n",
       "28           SOUTH OF JAVA, INDONESIA   15.76 \n",
       "29          PHILIPPINE ISLANDS REGION  119.18 \n",
       "30      FOX ISLANDS, ALEUTIAN ISLANDS   19.20 \n",
       "31           FLORES REGION, INDONESIA  155.42 \n",
       "32                    TARAPACA, CHILE   45.88 \n",
       "33      REVILLA GIGEDO ISLANDS REGION   16.01 \n",
       "34           SOUTH OF JAVA, INDONESIA   38.67 \n",
       "35                 PUERTO RICO REGION   29.05 \n",
       "36                     NORTHERN ITALY   30.77 \n",
       "37                        PUERTO RICO  177.04 \n",
       "38           ISLAND OF HAWAII, HAWAII   19.69 \n",
       "39                    SOUTHERN ALASKA   70.95 \n",
       "40                            ALBANIA   36.50 \n",
       "41                 PUERTO RICO REGION  141.00 \n",
       "42           SOUTH OF JAVA, INDONESIA   62.92 \n",
       "43                           SLOVENIA  150.52 \n",
       "44      MINAHASA, SULAWESI, INDONESIA   39.59 \n",
       "45        NORTHERN MID-ATLANTIC RIDGE   26.02 \n",
       "46      GOLFO DE FONSECA, EL SALVADOR   41.48 \n",
       "47                SULAWESI, INDONESIA   19.45 \n",
       "48                             FRANCE   36.26 \n",
       "49                     SOUTHERN IDAHO   95.20 "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"latitude\"] = pd.DataFrame(latitude)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "      <td>34.59</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORTHERN SUMATRA, INDONESIA</td>\n",
       "      <td>118.80</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>96.56</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOUTHERN SUMATRA, INDONESIA</td>\n",
       "      <td>35.15</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>27.79</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>38.22</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DODECANESE ISLANDS, GREECE</td>\n",
       "      <td>38.76</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRETE, GREECE</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>103.03</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHAGOS ARCHIPELAGO REGION</td>\n",
       "      <td>17.96</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KEPULAUAN BABAR, INDONESIA</td>\n",
       "      <td>66.83</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "      <td>19.22</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KOSOVO *</td>\n",
       "      <td>155.42</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LUZON, PHILIPPINES</td>\n",
       "      <td>35.15</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>27.83</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CROATIA</td>\n",
       "      <td>34.69</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AZORES ISLANDS, PORTUGAL</td>\n",
       "      <td>23.57</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KERMADEC ISLANDS, NEW ZEALAND</td>\n",
       "      <td>17.93</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "      <td>66.95</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEAR EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>5.32</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CENTRAL ALASKA</td>\n",
       "      <td>68.69</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NEAR THE COAST OF WESTERN TURKEY</td>\n",
       "      <td>7.31</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ADRIATIC SEA</td>\n",
       "      <td>129.32</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>33.25</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>OFFSHORE GUERRERO, MEXICO</td>\n",
       "      <td>116.64</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>42.11</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "      <td>20.70</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>15.76</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PHILIPPINE ISLANDS REGION</td>\n",
       "      <td>119.18</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FOX ISLANDS, ALEUTIAN ISLANDS</td>\n",
       "      <td>19.20</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>155.42</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "      <td>45.88</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>REVILLA GIGEDO ISLANDS REGION</td>\n",
       "      <td>16.01</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>38.67</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>29.05</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "      <td>30.77</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>177.04</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>19.69</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SOUTHERN ALASKA</td>\n",
       "      <td>70.95</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>36.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>141.00</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>62.92</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SLOVENIA</td>\n",
       "      <td>150.52</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>MINAHASA, SULAWESI, INDONESIA</td>\n",
       "      <td>39.59</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NORTHERN MID-ATLANTIC RIDGE</td>\n",
       "      <td>26.02</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>GOLFO DE FONSECA, EL SALVADOR</td>\n",
       "      <td>41.48</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "      <td>19.45</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FRANCE</td>\n",
       "      <td>36.26</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "      <td>95.20</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0 latitude longitude\n",
       "0                 SOUTHERN CALIFORNIA   34.59        N  \n",
       "1         NORTHERN SUMATRA, INDONESIA  118.80        W  \n",
       "2          DODECANESE ISLANDS, GREECE    4.39        2.2\n",
       "3                      EASTERN TURKEY   96.56        N  \n",
       "4         SOUTHERN SUMATRA, INDONESIA   35.15        E  \n",
       "5                         PUERTO RICO   27.79        2.5\n",
       "6            ISLAND OF HAWAII, HAWAII   38.22        N  \n",
       "7          DODECANESE ISLANDS, GREECE   38.76        E  \n",
       "8                       CRETE, GREECE    2.88        3.2\n",
       "9                  PUERTO RICO REGION  103.03        N  \n",
       "10          CHAGOS ARCHIPELAGO REGION   17.96        E  \n",
       "11         KEPULAUAN BABAR, INDONESIA   66.83        2.4\n",
       "12                SOUTHERN CALIFORNIA   19.22        S  \n",
       "13                           KOSOVO *  155.42        E  \n",
       "14                 LUZON, PHILIPPINES   35.15        2.7\n",
       "15           ISLAND OF HAWAII, HAWAII   27.83        N  \n",
       "16                            CROATIA   34.69        W  \n",
       "17           AZORES ISLANDS, PORTUGAL   23.57        2.6\n",
       "18      KERMADEC ISLANDS, NEW ZEALAND   17.93        N  \n",
       "19                 DOMINICAN REPUBLIC   66.95        W  \n",
       "20   NEAR EAST COAST OF HONSHU, JAPAN    5.32        2.3\n",
       "21                     CENTRAL ALASKA   68.69        N  \n",
       "22   NEAR THE COAST OF WESTERN TURKEY    7.31        E  \n",
       "23                       ADRIATIC SEA  129.32        4.1\n",
       "24                           OKLAHOMA   33.25        N  \n",
       "25          OFFSHORE GUERRERO, MEXICO  116.64        E  \n",
       "26                 PUERTO RICO REGION   42.11        3.1\n",
       "27                     WESTERN TURKEY   20.70        N  \n",
       "28           SOUTH OF JAVA, INDONESIA   15.76        W  \n",
       "29          PHILIPPINE ISLANDS REGION  119.18        2.6\n",
       "30      FOX ISLANDS, ALEUTIAN ISLANDS   19.20        S  \n",
       "31           FLORES REGION, INDONESIA  155.42        E  \n",
       "32                    TARAPACA, CHILE   45.88        5.2\n",
       "33      REVILLA GIGEDO ISLANDS REGION   16.01        S  \n",
       "34           SOUTH OF JAVA, INDONESIA   38.67        E  \n",
       "35                 PUERTO RICO REGION   29.05        4.7\n",
       "36                     NORTHERN ITALY   30.77        N  \n",
       "37                        PUERTO RICO  177.04        W  \n",
       "38           ISLAND OF HAWAII, HAWAII   19.69        2.1\n",
       "39                    SOUTHERN ALASKA   70.95        N  \n",
       "40                            ALBANIA   36.50        E  \n",
       "41                 PUERTO RICO REGION  141.00        2.4\n",
       "42           SOUTH OF JAVA, INDONESIA   62.92        N  \n",
       "43                           SLOVENIA  150.52        E  \n",
       "44      MINAHASA, SULAWESI, INDONESIA   39.59        3.6\n",
       "45        NORTHERN MID-ATLANTIC RIDGE   26.02        N  \n",
       "46      GOLFO DE FONSECA, EL SALVADOR   41.48        W  \n",
       "47                SULAWESI, INDONESIA   19.45        2.0\n",
       "48                             FRANCE   36.26        N  \n",
       "49                     SOUTHERN IDAHO   95.20        E  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"longitude\"] = pd.DataFrame(longitude)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO CONSIGO SEPARAR LATITUDE Y LONGITUDE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "hack_res = requests.get(url)\n",
    "\n",
    "hack_soup = BeautifulSoup(hack_res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_res = requests.get(url)\n",
    "\n",
    "twitter_soup = BeautifulSoup(twitter_res.text)\n",
    "\n",
    "#NO HE CONSEGUIDO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO HE CONSEGUIDO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_res = requests.get(url)\n",
    "\n",
    "lang_soup = BeautifulSoup(lang_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnglish\\n6\\xa0050\\xa0000+ articles\\n'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = lang_soup.select(\".link-box\")\n",
    "languages[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English\\n6\\xa0050\\xa0000+ articles',\n",
       " 'EspaÃ±ol\\n1\\xa0588\\xa0000+ artÃ\\xadculos',\n",
       " 'æ\\x97¥æ\\x9c¬èª\\x9e\\n1\\xa0198\\xa0000+ è¨\\x98äº\\x8b',\n",
       " 'Deutsch\\n2\\xa0416\\xa0000+ Artikel',\n",
       " 'FranÃ§ais\\n2\\xa0197\\xa0000+ articles',\n",
       " 'Ð\\xa0Ñ\\x83Ñ\\x81Ñ\\x81ÐºÐ¸Ð¹\\n1\\xa0611\\xa0000+ Ñ\\x81Ñ\\x82Ð°Ñ\\x82ÐµÐ¹',\n",
       " 'Italiano\\n1\\xa0595\\xa0000+ voci',\n",
       " 'ä¸\\xadæ\\x96\\x87\\n1\\xa0109\\xa0000+ æ¢\\x9dç\\x9b®',\n",
       " 'PortuguÃªs\\n1\\xa0027\\xa0000+ artigos',\n",
       " 'Polski\\n1\\xa0399\\xa0000+ haseÅ\\x82']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_lang = [lang.text.strip(\"\\n\") for lang in languages]\n",
    "lst_lang\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-784a0b919997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#https://openweathermap.org/current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter the city:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://api.openweathermap.org/data/2.5/weather?'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'q='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
